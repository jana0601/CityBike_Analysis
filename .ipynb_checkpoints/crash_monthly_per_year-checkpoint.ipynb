{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b97649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbff6081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0  trip_count\n",
      "0    2013-06      577702\n",
      "1    2013-07      843417\n",
      "2    2013-08     1001958\n",
      "3    2013-09     1034359\n",
      "4    2013-10     1037712\n",
      "5    2013-11      675774\n",
      "6    2013-12      443966\n",
      "     tripduration           starttime             stoptime  start_station_id  \\\n",
      "0            1354 2013-06-03 17:08:18  2013-06-03 17:30:52               311   \n",
      "1            1525 2013-06-05 17:34:04  2013-06-05 17:59:29               352   \n",
      "2             627 2013-06-05 18:00:34  2013-06-05 18:11:01               352   \n",
      "3            1154 2013-06-06 12:19:17  2013-06-06 12:38:31               152   \n",
      "4             866 2013-06-06 18:33:21  2013-06-06 18:47:47               375   \n",
      "..            ...                 ...                  ...               ...   \n",
      "197           396 2013-12-07 17:00:26  2013-12-07 17:07:02               410   \n",
      "198           761 2013-12-07 20:16:33  2013-12-07 20:29:14               507   \n",
      "199           396 2013-12-07 20:30:42  2013-12-07 20:37:18               290   \n",
      "200           327 2013-12-16 10:49:18  2013-12-16 10:54:45               505   \n",
      "201           605 2013-12-18 11:00:36  2013-12-18 11:10:41              2004   \n",
      "\n",
      "            start station name  start station latitude  \\\n",
      "0       Norfolk St & Broome St               40.717227   \n",
      "1              W 56 St & 6 Ave               40.763406   \n",
      "2              W 56 St & 6 Ave               40.763406   \n",
      "3        Warren St & Church St               40.714740   \n",
      "4    Mercer St & Bleecker St S               40.726795   \n",
      "..                         ...                     ...   \n",
      "197    Suffolk St & Stanton St               40.720664   \n",
      "198            E 25 St & 2 Ave               40.739126   \n",
      "199            2 Ave & E 58 St               40.760203   \n",
      "200            6 Ave & W 33 St               40.749013   \n",
      "201          6 Ave & Broome St               40.724399   \n",
      "\n",
      "     start station longitude  end_station_id          end station name  \\\n",
      "0                 -73.988021           532.0           S 5 Pl & S 5 St   \n",
      "1                 -73.977225           116.0           W 17 St & 8 Ave   \n",
      "2                 -73.977225           529.0           W 42 St & 8 Ave   \n",
      "3                 -74.009106           402.0        Broadway & E 22 St   \n",
      "4                 -73.996951           477.0           W 41 St & 8 Ave   \n",
      "..                       ...             ...                       ...   \n",
      "197               -73.985180           439.0            E 4 St & 2 Ave   \n",
      "198               -73.979738           290.0           2 Ave & E 58 St   \n",
      "199               -73.964785          2017.0           E 43 St & 2 Ave   \n",
      "200               -73.988484           472.0        E 32 St & Park Ave   \n",
      "201               -74.004704           151.0  Cleveland Pl & Spring St   \n",
      "\n",
      "     end station latitude  ...  bike_id    usertype birth year gender  \\\n",
      "0               40.710451  ...    14589    Customer        NaN      0   \n",
      "1               40.741776  ...    19061    Customer        NaN      0   \n",
      "2               40.757570  ...    19304  Subscriber     1961.0      1   \n",
      "3               40.740343  ...    20262    Customer        NaN      0   \n",
      "4               40.756405  ...    16554    Customer        NaN      0   \n",
      "..                    ...  ...      ...         ...        ...    ...   \n",
      "197             40.726281  ...    19289  Subscriber       1990      1   \n",
      "198             40.760203  ...    15935  Subscriber       1987      1   \n",
      "199             40.750224  ...    17540  Subscriber       1969      1   \n",
      "200             40.745712  ...    17095  Subscriber       1986      1   \n",
      "201             40.721816  ...    16646  Subscriber       1968      1   \n",
      "\n",
      "     crash_match_type matched_crash_id  dist_to_crash_start_m  \\\n",
      "0                 end           196110            2472.389650   \n",
      "1               start            41550              87.876854   \n",
      "2               start            41550              87.876854   \n",
      "3                 end            24089            3319.854221   \n",
      "4                 end            29232            3284.127323   \n",
      "..                ...              ...                    ...   \n",
      "197             start            13630              76.082733   \n",
      "198               end            36896            2638.507757   \n",
      "199             start            36896              24.447408   \n",
      "200               end            31282             633.253279   \n",
      "201               end             8975             773.224413   \n",
      "\n",
      "     dist_to_crash_end_m  year  month  \n",
      "0              87.009892  2013      6  \n",
      "1            3074.756472  2013      6  \n",
      "2            1240.399169  2013      6  \n",
      "3              73.856571  2013      6  \n",
      "4              77.754844  2013      6  \n",
      "..                   ...   ...    ...  \n",
      "197           807.253419  2013     12  \n",
      "198            24.447408  2013     12  \n",
      "199          1212.158196  2013     12  \n",
      "200            29.493102  2013     12  \n",
      "201            88.950787  2013     12  \n",
      "\n",
      "[202 rows x 21 columns]\n",
      "✅ Saved: results\\dataAnalysis\\2013\\monthly_usage_with_crashes.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def merge_usage_with_matched_crashes_2013():\n",
    "    # File paths\n",
    "    usage_file = r\"results\\dataAnalysis\\2013\\bike_usage_per_month.csv\"\n",
    "    matched_crash_file = r\"results\\matched_trips_2013.csv\"\n",
    "    output_file = r\"results\\dataAnalysis\\2013\\monthly_usage_with_crashes.csv\"\n",
    "\n",
    "    # Step 1: Load matched crash trips\n",
    "    try:\n",
    "        crashes = pd.read_csv(matched_crash_file)\n",
    "        if 'starttime' not in crashes.columns:\n",
    "            print(\"❌ 'starttime' column missing in matched_trips_2013.csv\")\n",
    "            return\n",
    "\n",
    "        crashes['starttime'] = pd.to_datetime(crashes['starttime'], errors='coerce')\n",
    "        crashes = crashes.dropna(subset=['starttime'])\n",
    "\n",
    "        crashes['year'] = crashes['starttime'].dt.year\n",
    "        crashes['month'] = crashes['starttime'].dt.month\n",
    "\n",
    "        # Step 2: Count crashes per month\n",
    "        crash_counts = crashes.groupby(['year', 'month']).size().reset_index(name='crash_count')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to process matched_trips_2013.csv: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Load bike usage\n",
    "    try:\n",
    "        usage = pd.read_csv(usage_file)\n",
    "        print(usage)\n",
    "        usage.columns = ['time', 'trip_count']\n",
    "        usage['time'] = pd.to_datetime(usage['time'], errors='coerce')\n",
    "        usage['year'] = usage['time'].dt.year\n",
    "        usage['month'] = usage['time'].dt.month\n",
    "        usage = usage.drop(columns=['time'])\n",
    "        #usage['trip_count'] = usage['trip_count']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load bike usage data: {e}\")\n",
    "        return\n",
    "    print(crashes)\n",
    "    # Step 4: Merge usage and crash counts\n",
    "    merged = pd.merge(usage, crash_counts, on=['year', 'month'], how='left')\n",
    "    merged['crash_count'] = merged['crash_count'].fillna(0).astype(int)\n",
    "\n",
    "    # After merging\n",
    "    merged['trip_count'] = pd.to_numeric(merged['trip_count'], errors='coerce')\n",
    "    merged['crash_count'] = pd.to_numeric(merged['crash_count'], errors='coerce')\n",
    "\n",
    "    # Fill any missing values just in case\n",
    "    merged['trip_count'] = merged['trip_count'].fillna(0).astype(int)\n",
    "    merged['crash_count'] = merged['crash_count'].fillna(0).astype(int)\n",
    "\n",
    "    # Now safe to calculate percentage\n",
    "    merged['percentage'] = (merged['crash_count'] / merged['trip_count'].replace(0, pd.NA)) * 100\n",
    "    merged['percentage'] = merged['percentage'].fillna(0)#.round(2)\n",
    "\n",
    "    # Step 6: Reorder columns\n",
    "    merged = merged[['year', 'month', 'trip_count', 'crash_count', 'percentage']]\n",
    "    merged = merged.sort_values(by=['year', 'month'])\n",
    "\n",
    "    # Step 7: Save\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    merged.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Saved: {output_file}\")\n",
    "\n",
    "# Run it\n",
    "merge_usage_with_matched_crashes_2013()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd757e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c71b91af",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5a63840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📅 Processing year: 2013\n",
      "✅ Saved: results/dataAnalysis/2013/monthly_usage_with_crashes.csv\n",
      "\n",
      "📅 Processing year: 2014\n",
      "✅ Saved: results/dataAnalysis/2014/monthly_usage_with_crashes.csv\n",
      "\n",
      "📅 Processing year: 2015\n",
      "✅ Saved: results/dataAnalysis/2015/monthly_usage_with_crashes.csv\n",
      "\n",
      "📅 Processing year: 2016\n",
      "✅ Saved: results/dataAnalysis/2016/monthly_usage_with_crashes.csv\n",
      "\n",
      "📅 Processing year: 2017\n",
      "✅ Saved: results/dataAnalysis/2017/monthly_usage_with_crashes.csv\n",
      "\n",
      "📅 Processing year: 2018\n",
      "✅ Saved: results/dataAnalysis/2018/monthly_usage_with_crashes.csv\n",
      "\n",
      "📅 Processing year: 2019\n",
      "✅ Saved: results/dataAnalysis/2019/monthly_usage_with_crashes.csv\n",
      "\n",
      "📅 Processing year: 2020\n",
      "✅ Saved: results/dataAnalysis/2020/monthly_usage_with_crashes.csv\n",
      "\n",
      "📅 Processing year: 2021\n",
      "✅ Saved: results/dataAnalysis/2021/monthly_usage_with_crashes.csv\n",
      "\n",
      "📅 Processing year: 2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanhu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1204: RuntimeWarning: invalid value encountered in cast\n",
      "  if not (lk == lk.astype(rk.dtype))[~np.isnan(lk)].all():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: results/dataAnalysis/2022/monthly_usage_with_crashes.csv\n",
      "\n",
      "📅 Processing year: 2023\n",
      "✅ Saved: results/dataAnalysis/2023/monthly_usage_with_crashes.csv\n",
      "\n",
      "📅 Processing year: 2024\n",
      "❌ Failed to process crash file for 2024: [Errno 2] No such file or directory: 'results/matched_trips_2024.csv'\n",
      "\n",
      "📅 Processing year: 2025\n",
      "❌ Failed to process crash file for 2025: [Errno 2] No such file or directory: 'results/matched_trips_2025.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def merge_usage_with_matched_crashes(year):\n",
    "    usage_file = f\"results/dataAnalysis/{year}/bike_usage_per_month.csv\"\n",
    "    matched_crash_file = f\"results/matched_trips_{year}.csv\"\n",
    "    output_file = f\"results/dataAnalysis/{year}/monthly_usage_with_crashes.csv\"\n",
    "\n",
    "    # Step 1: Load matched crash trips\n",
    "    try:\n",
    "        crashes = pd.read_csv(matched_crash_file)\n",
    "        if 'starttime' not in crashes.columns:\n",
    "            print(f\"❌ 'starttime' missing in {matched_crash_file}\")\n",
    "            return\n",
    "\n",
    "        crashes['starttime'] = pd.to_datetime(crashes['starttime'], errors='coerce')\n",
    "        crashes = crashes.dropna(subset=['starttime'])\n",
    "        crashes['year'] = crashes['starttime'].dt.year\n",
    "        crashes['month'] = crashes['starttime'].dt.month\n",
    "        crash_counts = crashes.groupby(['year', 'month']).size().reset_index(name='crash_count')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to process crash file for {year}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 2: Load bike usage\n",
    "    try:\n",
    "        usage = pd.read_csv(usage_file, header=None if year == '2013' else 'infer')\n",
    "        \n",
    "        # Handle missing headers (e.g., for 2013 file)\n",
    "        if usage.shape[1] == 2:\n",
    "            usage.columns = ['time', 'trip_count']\n",
    "        usage['time'] = pd.to_datetime(usage['time'], errors='coerce')\n",
    "        usage['year'] = usage['time'].dt.year\n",
    "        usage['month'] = usage['time'].dt.month\n",
    "        usage = usage.drop(columns=['time'])\n",
    "        usage['trip_count'] = pd.to_numeric(usage['trip_count'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to load usage data for {year}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Step 3: Merge\n",
    "    merged = pd.merge(usage, crash_counts, on=['year', 'month'], how='left')\n",
    "    merged['crash_count'] = pd.to_numeric(merged['crash_count'], errors='coerce').fillna(0).astype(int)\n",
    "    merged = merged[merged['trip_count'] > 0]  # Remove any bad rows with 0 trips\n",
    "\n",
    "    # Step 4: Calculate percentage\n",
    "    merged['percentage'] = (merged['crash_count'] / merged['trip_count'].replace(0, pd.NA)) * 100\n",
    "    merged['percentage'] = merged['percentage'].fillna(0)#.round(2)\n",
    "\n",
    "    # Step 5: Order and Save\n",
    "    merged = merged[['year', 'month', 'trip_count', 'crash_count', 'percentage']]\n",
    "    merged = merged.sort_values(by=['year', 'month'])\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    merged.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Saved: {output_file}\")\n",
    "\n",
    "\n",
    "# === Run for all available years ===\n",
    "def run_for_all_years():\n",
    "    base_dir = \"results/dataAnalysis\"\n",
    "    years = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d)) and d.isdigit()]\n",
    "    years.sort()  # Optional: sort years chronologically\n",
    "\n",
    "    for year in years:\n",
    "        print(f\"\\n📅 Processing year: {year}\")\n",
    "        merge_usage_with_matched_crashes(year)\n",
    "\n",
    "\n",
    "# Run it\n",
    "run_for_all_years()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d634b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb57f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
